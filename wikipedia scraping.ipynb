{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4837d51cd0df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'new/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mqq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'shahid afridi'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nawaz sharif'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Michael Jackson'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'barack obama'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'imran khan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mwiki_persnol_informations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-4837d51cd0df>\u001b[0m in \u001b[0;36mwiki_persnol_informations\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0;34m\"class\"\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m\"infobox vcard\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "import wikipedia\n",
    "import os \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# def wiki_data(name):\n",
    "#     wiki = wikipedia.page(name)\n",
    "#     return wiki\n",
    "# data = wiki_data(\"nawaz shareef\")\n",
    "\n",
    "\n",
    "# open wikipedia link for this particular person\n",
    "# os.system('firefox --new-window {}'.format(data.url))\n",
    "def wiki_persnol_informations(name):\n",
    "    data = wikipedia.page(name)\n",
    "    url = data.url\n",
    "    r  = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        html = r.text\n",
    "        soup = BeautifulSoup(html, 'lxml')\n",
    "    info = soup.find(\"table\", { \"class\" : \"infobox vcard\" }).select('tr')\n",
    "    ls = []\n",
    "    for i in range(len(info)):\n",
    "        try: \n",
    "            if 'background' in str(info[i].select_one('th')):\n",
    "                a = info[i].select_one('th').text\n",
    "                ls.append('th ' + 'background ' + a)\n",
    "            else:    \n",
    "                a = info[i].select_one('th').text\n",
    "                ls.append('th ' + a)\n",
    "            a = ''\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            b = info[i].select_one('td').text\n",
    "            ls.append('td ' + b)\n",
    "            b = ''\n",
    "        except: pass\n",
    "\n",
    "    a = [i.replace('\\n', '') for i in ls if i != '\\n']\n",
    "#     [i for i in a if i[:2] == 'th']\n",
    "    new = [i[3:] for i in a if len(i) > 3]\n",
    "    new = [i for i in new if i.lower() != 'signature']\n",
    "#     [i for i in new if i[:10] == 'background']\n",
    "\n",
    "    c = -1\n",
    "    m = 0\n",
    "    q = ''\n",
    "    for i in new:\n",
    "        c += 1\n",
    "        if i[:19] == 'background Personal':\n",
    "            start = new[c:]\n",
    "            q = 'ok'\n",
    "            break\n",
    "\n",
    "    if q == 'ok':\n",
    "        m = c\n",
    "        for i in new[c+1:]:\n",
    "            m += 1\n",
    "            if i[:10] == 'background':\n",
    "                pass\n",
    "                break\n",
    "    final = new[c+1:m]\n",
    "\n",
    "    # dict\n",
    "    # d = dict(zip([final[i] for i in range(0, len(final), 2)],[final[i] for i in range(1, len(final), 2)]))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    # df[data.original_title] = \n",
    "    df['key'] = [final[i] for i in range(0, len(final), 2)]\n",
    "    df['value'] = [final[i] for i in range(1, len(final), 2)]\n",
    "    df.to_csv('{}.csv'.format(''.join(data.original_title.split())))\n",
    "#     os.system('libreoffice {}.csv'.format(''.join(data.original_title.split())))\n",
    "# for i in ['shahid afridi', 'nawaz shareef', 'barack obama', 'imran khan']:\n",
    "try:\n",
    "    os.system(\"rm -rf /home/amir/Desktop/github/working/new\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "os.mkdir('new')\n",
    "os.chdir('new/')\n",
    "for qq in ['nawaz sharif','barack obama','imran khan']:#'Michael Jackson','shahid afridi',\n",
    "    wiki_persnol_informations(qq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "a = 'https://www.mediawiki.org/wiki/Special:MyLanguage/API:Parsing_wikitext#parse'\n",
    "a = 'https://en.wikipedia.org/wiki/Nawaz_Sharif'\n",
    "'api.php?action=parse&page=Project:Sandbox'\n",
    "os.system('firefox {}'.format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_sections(sections, level=0):\n",
    "        for s in sections:\n",
    "                print(\"%s: %s - %s\" % (\"*\" * (level + 1), s.title, s.text[0:40]))\n",
    "                print_sections(s.sections, level + 1)\n",
    "\n",
    "\n",
    "print_sections(page_py.sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def print_categories(page):\n",
    "        categories = page.categories\n",
    "        for title in sorted(categories.keys()):\n",
    "            print(\"%s: %s\" % (title, categories[title]))\n",
    "\n",
    "\n",
    "# print(\"Categories\")\n",
    "print_categories(page_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = soup.select('.mw-body-content > mw-parser-output')\n",
    "for i in soup.select('.mw-body-content > .mw-content-ltr > .mw-parser-output'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i in soup.find(\"table\", { \"class\" : \"infobox vcard\" }).text.split('\\n'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# usefull function\n",
    "def summary(query):\n",
    "    pages = list()\n",
    "    if len(query.strip()) <= 0:\n",
    "        raise ValueError\n",
    "    SEARCH_URL = 'https://en.wikipedia.org/wiki/'\n",
    "    response = requests.get(SEARCH_URL + str(query))\n",
    "    soup = BeautifulSoup(markup=response.text, features=\"lxml\")\n",
    "\n",
    "    if soup is None:\n",
    "        raise Exception\n",
    "\n",
    "    if \"search\" in str(soup.title).lower():\n",
    "        result_ul = soup.find(name=\"ul\", attrs={\"class\": \"mw-search-results\"})\n",
    "        results_list = result_ul.find_all(\"li\")\n",
    "\n",
    "        for li in results_list:\n",
    "            li_div = li.find(name=\"div\", attrs={\"class\": \"mw-search-result-heading\"})\n",
    "            a = li_div.find(\"a\")\n",
    "            link = \"https://en.wikipedia.org\" + a[\"href\"]\n",
    "            heading = str(a.text)\n",
    "            pages.append((link, heading))\n",
    "\n",
    "        return pages\n",
    "    else:\n",
    "        return wikipedia.summary(query) \n",
    "summary('Nawaz_Sharif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/martin-majlis/Wikipedia-API\n",
    "https://github.com/goldsmith/Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
